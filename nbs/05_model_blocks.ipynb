{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7d452e5-c5e1-48d6-8314-9a9dd8605aac",
   "metadata": {},
   "source": [
    "# Model Blocks\n",
    "\n",
    "Contains the building blocks for models in including conv blocks, resblocks etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4b91c5-f072-4a65-a938-09b0de416297",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp model_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075b21df-5aae-4cca-8629-040b5f061d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import pickle,gzip,math,os,time,shutil,torch,matplotlib as mpl, numpy as np\n",
    "import pandas as pd,matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from torch import tensor\n",
    "from torch import nn\n",
    "\n",
    "from torch.utils.data import DataLoader,default_collate\n",
    "from typing import Mapping\n",
    "\n",
    "from miniai.datasets import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf9a4d2-aa94-4bb0-9a5b-2c99a547381c",
   "metadata": {},
   "source": [
    "Add a basic convolutional block, which is a fundamental building block of more complex blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0390da-122d-4511-9e46-18279ff05ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temp\n",
    "class GeneralRelu(nn.Module):\n",
    "    def __init__(self, leak=None, sub=None, maxv=None):\n",
    "        super().__init__()\n",
    "        self.leak, self.sub, self. maxv = leak, sub, maxv\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(x, self.leak) if self.leak is not None else F.relu(x)\n",
    "        if self.sub is not None: x -= self.sub\n",
    "        if self.maxv is not None: x = x.clamp_max_(self.maxv)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54641cb1-1654-4246-a4bd-e4b8a1915b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temp\n",
    "act_gr = partial(GeneralRelu, leak=0.1, sub=0.4)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "643be912-6f5c-497c-ba68-a845c51a467b",
   "metadata": {},
   "source": [
    "#|export\n",
    "def conv(\n",
    "    ni: int, # Input length\n",
    "    nch: int, # number of channels output\n",
    "    ks: int=3, # Kernel size (should be an odd number)\n",
    "    stride: int=2, # Stride\n",
    "    act: bool=True # Whether to assign an activation layer to the output\n",
    "):\n",
    "    out = nn.Conv2d(ni, nch, kernel_size=ks, stride=stride, padding=ks//2)\n",
    "    if act: out = nn.Sequential(out, nn.ReLU())\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49625b1-6687-4469-94e0-1cb83a2437ba",
   "metadata": {},
   "source": [
    "### Conv Block\n",
    "Conv from notebook 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fab78f9-77f3-4a64-824b-0e9703cd343c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def conv(ni, # Input filters\n",
    "         nf, # Output filters\n",
    "         ks=3, # Kernel size\n",
    "         stride=2, # Stride,\n",
    "         padding=None, # Padding\n",
    "         act=nn.ReLU, # Activation\n",
    "         norm=None, # Type of normalization layer to apply\n",
    "         bias=None # Whether to apply bias\n",
    "        )-> nn.Sequential:\n",
    "    \"\"\" Generate a conv block with a conv layer and optional normalisation and activation. If bias \n",
    "    is None then the bias is not applied  to the conv if batch norm is used, otherwise it is\n",
    "\n",
    "    Using ks=3 and padding=1 will result in the resolution reducing as per the stride, as will \n",
    "    ks=5 and padding=2\n",
    "\n",
    "    Returns the block as a sequential model\n",
    "    \"\"\"\n",
    "    if bias is None:\n",
    "        bias = not norm in (torch.nn.modules.batchnorm.BatchNorm1d, \n",
    "                            torch.nn.modules.batchnorm.BatchNorm2d, \n",
    "                            torch.nn.modules.batchnorm.BatchNorm3d)\n",
    "    if padding is None: padding=ks//2\n",
    "    layers = [nn.Conv2d(ni, nf, stride=stride, kernel_size=ks, padding=padding, bias=bias)]\n",
    "    if norm: layers.append(norm(nf))\n",
    "    if act: layers.append(act())\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3764d0-8d5d-43b9-bbe0-6ac7ab8af444",
   "metadata": {},
   "source": [
    "#### Conv Block Tests "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a21034-b310-4f24-b064-dff68d12fb63",
   "metadata": {},
   "source": [
    "Check conv block with defaults has the correct layers and properties.  Note that further tests can be added, these are basic starters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24847d1-71d3-48b6-80c9-7216729cdaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check conv block with defaults\n",
    "ni=3\n",
    "nf=6\n",
    "stride=2\n",
    "padding=1\n",
    "act=nn.ReLU\n",
    "norm=None\n",
    "bias=None\n",
    "conv_block = conv(ni=ni, nf=nf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829efa67-4fea-4234-a844-ef580b51cba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_bias(layer):\n",
    "    try:\n",
    "        bias = layer.get_parameter('bias')\n",
    "    except:\n",
    "        bias = None\n",
    "    return bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3493ff-e408-4661-b26c-dad74c3f9c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bias should exist since there is no norm by default\n",
    "assert check_if_bias(conv_block[0]) is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339d54ea-448a-4e7b-8939-e65adaccd0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm there are only two layers (conv and activation)\n",
    "assert len(conv_block) == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3b0bbf-8f41-4a79-bc6f-60d408a29a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that when batchnorm is applied then the bias is deactivated unless specified\n",
    "norm = nn.BatchNorm2d\n",
    "bias = None\n",
    "conv_block = conv(ni=ni, nf=nf, norm=norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d928eaee-e89b-4ebd-b4fc-773a2e0a1611",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert check_if_bias(conv_block[0]) is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce27d460-f479-424f-b8bd-245a7b1b8608",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(conv_block) ==3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838fc7b4-690c-4f1b-8054-930daa5e1f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that when batchnorm is applied then and bias is specified then it is assigned\n",
    "norm=nn.BatchNorm2d\n",
    "bias=True\n",
    "conv_block = conv(ni=ni, nf=nf, norm=norm, bias=bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe94e0b-2cc1-4005-aa6c-52f71d0d4591",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert check_if_bias(conv_block[0]) is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837af15f-8e00-4a46-aed8-59c1547e694c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that if activation is None then that layer is not added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9011b9-a3de-4493-946c-4677ce7bc3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_block = conv(ni=ni, nf=nf, norm=norm, bias=bias, act=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067be4ad-a7f0-4109-9247-cf54f93dfa04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_block[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c5124c-3ff8-4426-90cb-5ea419c9a3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(conv_block[-1], nn.BatchNorm2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abae0a85-845b-4318-882b-7607de5add75",
   "metadata": {},
   "source": [
    "### ResBlock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a451564-1b4d-4045-bcca-4320baeacd6a",
   "metadata": {},
   "source": [
    "Add a conv_block which is the two conv layers used in the ResBlock (from notebook 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f953978-e6b0-41b3-a41e-dc2df4934aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def _conv_block(ni, # input channels\n",
    "                nf, # out channels\n",
    "                stride, # stride\n",
    "                ks=3, # kernel size\n",
    "                act=act_gr, # activation to use\n",
    "                norm=None # normalization to use\n",
    "               ):\n",
    "    \"\"\" Generates a sequential model consisting of two conv blocks.  Note that the architectual \n",
    "    choice being made here is that the first conv changes the number of channels and the second \n",
    "    keeps the number of channels the same but reduces the resolution by using stride=2\n",
    "\n",
    "    \"\"\"\n",
    "    return nn.Sequential(\n",
    "        conv(ni, nf, stride=1, ks=ks, act=act, norm=norm),\n",
    "        conv(nf, nf, stride=stride, ks=ks, act=None, norm=norm)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f68083-0476-4b5e-8d30-c2d74376c336",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    \"\"\" Create a traditional Resnet block with a conv block, a pass through path, a pooling layer and\n",
    "    an activation.\n",
    "  \n",
    "    The pass through block uses a pooling layer to reduce the resolution if required and then a \n",
    "    basic conv to change the number of channels to that required to facilitate addition to the \n",
    "    conv block output\n",
    "\n",
    "    The forward method will feed data though the block\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 ni, # input channels\n",
    "                 nf, # out channels\n",
    "                 stride=1, # stride\n",
    "                 ks=3, # kernel size\n",
    "                 padding=None, # padding\n",
    "                 act=act_gr, # activation to use\n",
    "                 norm=None # normalization to use\n",
    "                ):\n",
    "        super().__init__()\n",
    "        # Create the two convolution layers\n",
    "        self.convs = _conv_block(ni, nf, stride, ks=ks, act=act, norm=norm)\n",
    "        # Create the pass through layer.  Note that this can only be a complete pass of the input if ni=nf.\n",
    "        # Where this is not the case a single conv is used (with no activation and kernel size of 1)\n",
    "        self.idconv = fc.noop if ni==nf else conv(ni, nf, stride=1, ks=1, act=None)\n",
    "        self.pool = fc.noop if stride==1 else nn.AvgPool2d(kernel_size=2, ceil_mode=True)\n",
    "        self.act = act()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.act(self.convs(x) + self.idconv(self.pool(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fad633-2efa-4dcb-a586-71f3fd2f197b",
   "metadata": {},
   "source": [
    "### Pre_conv\n",
    "\n",
    "Similar to a conv block but with the norm and activation layers ahead of the conv layers.  Found to work better in some cases including stable diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02095f2-c9e1-41fa-956f-229fdc561495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from diffusion.py\n",
    "def pre_conv(ni, # input channels\n",
    "             nf, # out channels\n",
    "             ks=3, # kernel size\n",
    "             stride=1, # stride\n",
    "             act=nn.SiLU, # activation to use\n",
    "             norm=None, # normalization to use\n",
    "             bias=True # whether to use bias for the conv layer\n",
    "            ):\n",
    "    \"\"\" Generate a conv block with a conv layer and optional normalisation and activation.\n",
    "    Bias and norm layers are optional. Using ks=3 and padding=1 will result in the resolution \n",
    "    reducing as per the stride, as will ks=5 and padding=2\n",
    "\n",
    "    Returns the block as a sequential model\n",
    "    \"\"\"\n",
    "    layers = nn.Sequential()\n",
    "    if norm: layers.append(norm(ni))\n",
    "    if act : layers.append(act())\n",
    "    layers.append(nn.Conv2d(ni, nf, stride=stride, kernel_size=ks, padding=ks//2, bias=bias))\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba760ea6-9f6f-47e9-8989-03097b2c2959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: tests for pre_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9bca8a-1d53-42f7-a789-0a7eb6e31cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(nf): return nn.Sequential(nn.Upsample(scale_factor=2.), nn.Conv2d(nf, nf, 3, padding=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8e8e2a-3c5b-4c2f-8fd2-a00a66c8e1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin(ni, nf, act=nn.SiLU, norm=None, bias=True):\n",
    "    layers = nn.Sequential()\n",
    "    if norm: layers.append(norm(ni))\n",
    "    if act : layers.append(act())\n",
    "    layers.append(nn.Linear(ni, nf, bias=bias))\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fb057a-d4e2-4244-a5de-37c42b7af955",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, ni, attn_chans, transpose=True):\n",
    "        super().__init__()\n",
    "        self.nheads = ni//attn_chans\n",
    "        self.scale = math.sqrt(ni/self.nheads)\n",
    "        self.norm = nn.LayerNorm(ni)\n",
    "        self.qkv = nn.Linear(ni, ni*3)\n",
    "        self.proj = nn.Linear(ni, ni)\n",
    "        self.t = transpose\n",
    "    \n",
    "    def forward(self, x):\n",
    "        n,c,s = x.shape\n",
    "        if self.t: x = x.transpose(1, 2)\n",
    "        x = self.norm(x)\n",
    "        x = self.qkv(x)\n",
    "        x = rearrange(x, 'n s (h d) -> (n h) s d', h=self.nheads)\n",
    "        q,k,v = torch.chunk(x, 3, dim=-1)\n",
    "        s = (q@k.transpose(1,2))/self.scale\n",
    "        x = s.softmax(dim=-1)@v\n",
    "        x = rearrange(x, '(n h) s d -> n s (h d)', h=self.nheads)\n",
    "        x = self.proj(x)\n",
    "        if self.t: x = x.transpose(1, 2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e1752b-9d23-4020-9dc2-28b89c154783",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention2D(SelfAttention):\n",
    "    def forward(self, x):\n",
    "        n,c,h,w = x.shape\n",
    "        return super().forward(x.view(n, c, -1)).reshape(n,c,h,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf60aa14-594b-4592-9c3a-2515e4f7e17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbResBlock(nn.Module):\n",
    "    def __init__(self, n_emb, ni, nf=None, ks=3, act=nn.SiLU, norm=nn.BatchNorm2d, attn_chans=0):\n",
    "        super().__init__()\n",
    "        if nf is None: nf = ni\n",
    "        self.emb_proj = nn.Linear(n_emb, nf*2)\n",
    "        self.conv1 = pre_conv(ni, nf, ks, act=act, norm=norm)\n",
    "        self.conv2 = pre_conv(nf, nf, ks, act=act, norm=norm)\n",
    "        self.idconv = fc.noop if ni==nf else nn.Conv2d(ni, nf, 1)\n",
    "        self.attn = False\n",
    "        if attn_chans: self.attn = SelfAttention2D(nf, attn_chans)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        inp = x\n",
    "        x = self.conv1(x)\n",
    "        emb = self.emb_proj(F.silu(t))[:, :, None, None]\n",
    "        scale,shift = torch.chunk(emb, 2, dim=1)\n",
    "        x = x*(1+scale) + shift\n",
    "        x = self.conv2(x)\n",
    "        x = x + self.idconv(inp)\n",
    "        if self.attn: x = x + self.attn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b2dcbb-b1d5-4ecf-927d-46a47351ab66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
