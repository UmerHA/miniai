{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "685dbec5-24c8-4714-aec8-4a1b199b35d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "! pip install -qq -e .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b172ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e8f8491",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import math,torch,matplotlib.pyplot as plt\n",
    "import fastcore.all as fc\n",
    "from collections.abc import Mapping\n",
    "from operator import attrgetter\n",
    "from functools import partial\n",
    "from copy import copy\n",
    "\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from miniai.datasets import *\n",
    "from miniai.plotting import *\n",
    "from miniai.utils import *\n",
    "\n",
    "from fastprogress import progress_bar,master_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8866c6-8b4a-494d-a8e5-324ea6593191",
   "metadata": {},
   "source": [
    "We will make the `Learner` flexible by allowing callbacks at every point. Therefore, we first define some callback utility functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "534c00e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class CancelFitException(Exception): pass\n",
    "class CancelBatchException(Exception): pass\n",
    "class CancelEpochException(Exception): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee43512e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class Callback(): order = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7439ca0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def run_cbs(cbs, method_nm, learn=None):\n",
    "    for cb in sorted(cbs, key=attrgetter('order')):\n",
    "        method = getattr(cb, method_nm, None)\n",
    "        if method is not None: method(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1271ae6-de9c-4ef4-92ef-26b7419b1f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyLearner():\n",
    "    def __init__(self, name): self.name,self.greetings = name, []\n",
    "\n",
    "class DummyCallback(Callback):\n",
    "    def __init__(self, greeting): self.greeting = greeting\n",
    "    def greet(self, learn): learn.greetings.append(self.greeting + ' ' + learn.name)\n",
    "\n",
    "john, umer = DummyLearner('John'), DummyLearner('Umer')\n",
    "cb_hi, cb_hello = DummyCallback('Hi'), DummyCallback('Hello')\n",
    "\n",
    "cb_hi_low_priority = DummyCallback('Hi')\n",
    "cb_hi_low_priority.order = 1\n",
    "\n",
    "run_cbs([cb_hi, cb_hello], 'greet', john)\n",
    "run_cbs([cb_hi_low_priority, cb_hello], 'greet', umer)\n",
    "\n",
    "assert john.greetings == ['Hi John', 'Hello John']\n",
    "assert umer.greetings == ['Hello Umer', 'Hi Umer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1ddb822",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class with_cbs:\n",
    "    def __init__(self, nm): self.nm = nm\n",
    "    def __call__(self, f):\n",
    "        def _f(o, *args, **kwargs):\n",
    "            try:\n",
    "                o.callback(f'before_{self.nm}')\n",
    "                f(o, *args, **kwargs)\n",
    "                o.callback(f'after_{self.nm}')\n",
    "            except globals()[f'Cancel{self.nm.title()}Exception']: pass\n",
    "            finally: o.callback(f'cleanup_{self.nm}')\n",
    "        return _f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d185991-3107-415d-8814-e986589c95eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyLearner():\n",
    "    def __init__(self, cbs=None): self.cbs,self.notes = cbs,[]\n",
    "    def callback(self, method_nm): run_cbs(self.cbs, method_nm, self)\n",
    "\n",
    "    @with_cbs('call')\n",
    "    def call(self): self.notes.append('during call')\n",
    "\n",
    "    @with_cbs('call')\n",
    "    def call2(self): self.notes.append('during call2')\n",
    "\n",
    "class DummyCallback(Callback):\n",
    "    def before_call(self, learn): learn.notes.append('before call')\n",
    "    def after_call(self, learn): learn.notes.append('after call')\n",
    "\n",
    "\n",
    "dummy_learner = DummyLearner([DummyCallback()])\n",
    "dummy_learner.call()\n",
    "assert dummy_learner.notes == ['before call', 'during call', 'after call']\n",
    "\n",
    "dummy_learner = DummyLearner([DummyCallback()])\n",
    "dummy_learner.call2()\n",
    "assert dummy_learner.notes == ['before call', 'during call2', 'after call']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33c1a1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class Learner():\n",
    "    def __init__(self, model, dls=(0,), loss_func=F.mse_loss, lr=0.1, cbs=None, opt_func=optim.SGD):\n",
    "        cbs = fc.L(cbs)\n",
    "        fc.store_attr()\n",
    "\n",
    "    @with_cbs('batch')\n",
    "    def _one_batch(self):\n",
    "        self.predict()\n",
    "        self.callback('after_predict')\n",
    "        self.get_loss()\n",
    "        self.callback('after_loss')\n",
    "        if self.training:\n",
    "            self.backward()\n",
    "            self.callback('after_backward')\n",
    "            self.step()\n",
    "            self.callback('after_step')\n",
    "            self.zero_grad()\n",
    "\n",
    "    @with_cbs('epoch')\n",
    "    def _one_epoch(self):\n",
    "        for self.iter,self.batch in enumerate(self.dl): self._one_batch()\n",
    "\n",
    "    def one_epoch(self, training):\n",
    "        self.model.train(training)\n",
    "        self.dl = self.dls.train if training else self.dls.valid\n",
    "        self._one_epoch()\n",
    "\n",
    "    @with_cbs('fit')\n",
    "    def _fit(self, train, valid):\n",
    "        for self.epoch in self.epochs:\n",
    "            if train: self.one_epoch(True)\n",
    "            if valid: torch.no_grad()(self.one_epoch)(False)\n",
    "\n",
    "    def fit(self, n_epochs=1, train=True, valid=True, cbs=None, lr=None):\n",
    "        cbs = fc.L(cbs)\n",
    "        for cb in cbs: self.cbs.append(cb)\n",
    "        try:\n",
    "            self.n_epochs = n_epochs\n",
    "            self.epochs = range(n_epochs)\n",
    "            if lr is None: lr = self.lr\n",
    "            if self.opt_func: self.opt = self.opt_func(self.model.parameters(), lr)\n",
    "            self._fit(train, valid)\n",
    "        finally:\n",
    "            for cb in cbs: self.cbs.remove(cb)\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        if name in ('predict','get_loss','backward','step','zero_grad'): return partial(self.callback, name)\n",
    "        raise AttributeError(name)\n",
    "\n",
    "    def callback(self, method_nm): run_cbs(self.cbs, method_nm, self)\n",
    "    \n",
    "    @property\n",
    "    def training(self): return self.model.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5c14d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SingleBatchCB(Callback):\n",
    "    order = 1\n",
    "    def after_batch(self, learn): raise CancelFitException()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6b6c8df-f329-4446-8ea2-caa8ca4a3779",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyModel(torch.nn.Module):\n",
    "    # def __init__(self): self.a = pass # todo: register some parameters\n",
    "    def forward(self,xb): return torch.zeros_like(xb)\n",
    "\n",
    "learn = Learner(DummyModel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c337e1fb-58bf-46f7-85e7-882c4bf6def4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DummyModel' object has no attribute 'parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mlearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[12], line 42\u001b[0m, in \u001b[0;36mLearner.fit\u001b[1;34m(self, n_epochs, train, valid, cbs, lr)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(n_epochs)\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt_func: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt_func(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m(), lr)\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(train, valid)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DummyModel' object has no attribute 'parameters'"
     ]
    }
   ],
   "source": [
    "learn.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78d0804-7136-4c97-abda-70496cc93441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67c006c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from torcheval.metrics import MulticlassAccuracy,Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678712dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class MetricsCB(Callback):\n",
    "    def __init__(self, *ms, **metrics):\n",
    "        for o in ms: metrics[type(o).__name__] = o\n",
    "        self.metrics = metrics\n",
    "        self.all_metrics = copy(metrics)\n",
    "        self.all_metrics['loss'] = self.loss = Mean()\n",
    "\n",
    "    def _log(self, d): print(d)\n",
    "    def before_fit(self, learn): learn.metrics = self\n",
    "    def before_epoch(self, learn): [o.reset() for o in self.all_metrics.values()]\n",
    "\n",
    "    def after_epoch(self, learn):\n",
    "        log = {k:f'{v.compute():.3f}' for k,v in self.all_metrics.items()}\n",
    "        log['epoch'] = learn.epoch\n",
    "        log['train'] = 'train' if learn.model.training else 'eval'\n",
    "        self._log(log)\n",
    "\n",
    "    def after_batch(self, learn):\n",
    "        x,y,*_ = to_cpu(learn.batch)\n",
    "        for m in self.metrics.values(): m.update(to_cpu(learn.preds), y)\n",
    "        self.loss.update(to_cpu(learn.loss), weight=len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339962be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class DeviceCB(Callback):\n",
    "    def __init__(self, device=def_device): fc.store_attr()\n",
    "    def before_fit(self, learn):\n",
    "        if hasattr(learn.model, 'to'): learn.model.to(self.device)\n",
    "    def before_batch(self, learn): learn.batch = to_device(learn.batch, device=self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee3643f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class TrainCB(Callback):\n",
    "    def __init__(self, n_inp=1): self.n_inp = n_inp\n",
    "    def predict(self, learn): learn.preds = learn.model(*learn.batch[:self.n_inp])\n",
    "    def get_loss(self, learn): learn.loss = learn.loss_func(learn.preds, *learn.batch[self.n_inp:])\n",
    "    def backward(self, learn): learn.loss.backward()\n",
    "    def step(self, learn): learn.opt.step()\n",
    "    def zero_grad(self, learn): learn.opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9537f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class ProgressCB(Callback):\n",
    "    order = MetricsCB.order+1\n",
    "    def __init__(self, plot=False): self.plot = plot\n",
    "    def before_fit(self, learn):\n",
    "        learn.epochs = self.mbar = master_bar(learn.epochs)\n",
    "        self.first = True\n",
    "        if hasattr(learn, 'metrics'): learn.metrics._log = self._log\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "\n",
    "    def _log(self, d):\n",
    "        if self.first:\n",
    "            self.mbar.write(list(d), table=True)\n",
    "            self.first = False\n",
    "        self.mbar.write(list(d.values()), table=True)\n",
    "\n",
    "    def before_epoch(self, learn): learn.dl = progress_bar(learn.dl, leave=False, parent=self.mbar)\n",
    "    def after_batch(self, learn):\n",
    "        learn.dl.comment = f'{learn.loss:.3f}'\n",
    "        if self.plot and hasattr(learn, 'metrics') and learn.training:\n",
    "            self.losses.append(learn.loss.item())\n",
    "            if self.val_losses: self.mbar.update_graph([[fc.L.range(self.losses), self.losses],[fc.L.range(learn.epoch).map(lambda x: (x+1)*len(learn.dls.train)), self.val_losses]])\n",
    "    \n",
    "    def after_epoch(self, learn): \n",
    "        if not learn.training:\n",
    "            if self.plot and hasattr(learn, 'metrics'): \n",
    "                self.val_losses.append(learn.metrics.all_metrics['loss'].compute())\n",
    "                self.mbar.update_graph([[fc.L.range(self.losses), self.losses],[fc.L.range(learn.epoch+1).map(lambda x: (x+1)*len(learn.dls.train)), self.val_losses]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fe2944",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class TrainLearner(Learner):\n",
    "    def predict(self): self.preds = self.model(self.batch[0])\n",
    "    def get_loss(self): self.loss = self.loss_func(self.preds, self.batch[1])\n",
    "    def backward(self): self.loss.backward()\n",
    "    def step(self): self.opt.step()\n",
    "    def zero_grad(self): self.opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68148d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class MomentumLearner(TrainLearner):\n",
    "    def __init__(self, model, dls, loss_func, lr=None, cbs=None, opt_func=optim.SGD, mom=0.85):\n",
    "        self.mom = mom\n",
    "        super().__init__(model, dls, loss_func, lr, cbs, opt_func)\n",
    "\n",
    "    def zero_grad(self):\n",
    "        with torch.no_grad():\n",
    "            for p in self.model.parameters(): p.grad *= self.mom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313fcb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from torch.optim.lr_scheduler import ExponentialLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd3748d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class LRFinderCB(Callback):\n",
    "    def __init__(self, gamma=1.3, max_mult=3): fc.store_attr()\n",
    "    \n",
    "    def before_fit(self, learn):\n",
    "        self.sched = ExponentialLR(learn.opt, self.gamma)\n",
    "        self.lrs,self.losses = [],[]\n",
    "        self.min = math.inf\n",
    "\n",
    "    def after_batch(self, learn):\n",
    "        if not learn.training: raise CancelEpochException()\n",
    "        self.lrs.append(learn.opt.param_groups[0]['lr'])\n",
    "        loss = to_cpu(learn.loss)\n",
    "        self.losses.append(loss)\n",
    "        if loss < self.min: self.min = loss\n",
    "        if math.isnan(loss) or (loss > self.min*self.max_mult):\n",
    "            raise CancelFitException()\n",
    "        self.sched.step()\n",
    "\n",
    "    def cleanup_fit(self, learn):\n",
    "        plt.plot(self.lrs, self.losses)\n",
    "        plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff226c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@fc.patch\n",
    "def lr_find(self:Learner, gamma=1.3, max_mult=3, start_lr=1e-5, max_epochs=10):\n",
    "    self.fit(max_epochs, lr=start_lr, cbs=LRFinderCB(gamma=gamma, max_mult=max_mult))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfb9bd2",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "465118f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc774ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
